---
output:
  pdf_document: default
  html_document: default
---

## **Classification de la gravité d'un accident**

Dans cette étude nous allons essayer de classifier la gravité d'un accident. Nous allons essayer de prédire les caractéristiques suivantes :

1 - L'accident est léger 2 - L'accident est grave

à partir de la colonne "grav":

1 -- Indemne (léger) 2 -- Tué (grave) 3 -- Blessé hospitalisé (grave) 4 -- Blessé léger (léger)

Afin de classifier nos données nous allons utiliser ces variables :

lum, agg, int, atm, col, catr, circ, surf, situ, infra, vma, choc, manv,obs ,obsm, catv, place, secu1, locp, actp, grav

Comme indiqué dans la description des bases de données, les données liées aux comportements des usagers ne sont pas divulguées dans la mesure où la divulgation de ces données porterait atteinte à la protection de la vie privée (dommage)

**I - Préparation de la Dataframe**

```{r}
#Conversions des csv en dataframe
caracteristiques_2021 <- read.csv("./caracteristiques/caracteristiques_2021.csv", sep = ";", header = TRUE)
lieux_2021 <- read.csv("./lieux/lieux_2021.csv", sep = ";", header = TRUE)
usagers_2021 <- read.csv("./usagers/usagers_2021.csv", sep = ";", header = TRUE)
vehicules_2021 <- read.csv("./vehicules/vehicules_2021.csv", sep = ";", header = TRUE)

#On merge les dataframes "caracteristiques_2021", "lieux_2021" et "usagers_2021" par rapport à Num_Acc et vehicule par rapport à id_vehicule
df <- merge(merge(merge(caracteristiques_2021, lieux_2021, by = "Num_Acc"), usagers_2021, by = "Num_Acc"), vehicules_2021, by = "id_vehicule")

#On ne conserve que les colonnes qui nous intéressent
df <- df[, c("lum", "agg", "int", "atm", "col", "catr", "circ", "surf", "situ", "infra", "vma", "choc", "manv", "obs", "obsm", "catv", "place", "secu1", "secu2", "secu3", "locp", "actp", "catu", "grav", "sexe")]

#Dans la colonne actp on remplace les valeurs "A" et "B" en int
df$actp <- ifelse(df$actp == "A", 10, ifelse(df$actp == "B", 11, df$actp))
df$actp <- as.numeric(df$actp)

df$grav <- ifelse(df$grav == 1, 0, ifelse(df$grav == 2, 1, ifelse(df$grav == 3, 1, ifelse(df$grav == 4, 0, df$grav))))

head(df)
```

Vérifions si nous avons besoin de supprimer des lignes nous donnant pas assez d'information

```{r}
library(plotly)

# On compte le nombre de -1 dans chaque colonne de df
nombre <- sapply(df, function(x) sum(x == -1))

# On visualise les colonnes ayant beaucoup de valeur non renseinées
fig <- plot_ly(x = names(nombre), y = nombre, type = "bar", 
               xaxis = list(title = "Colonnes"), yaxis = list(title = "Nombre de -1"),
               marker = list(color = "#4C78A8"))

fig <- fig %>% layout(title = "Nombre de valeurs manquantes par colonne")

fig
```

```{r}
# On filtre les lignes où la valeur de la colonne 'catu' est égale à 3
df_pieton <- df[df$catu == 3, ]

# On compte le nombre de -1 dans chaque colonne de df_filtered
nombre <- sapply(df_pieton, function(x) sum(x == -1))

# On visualise les colonnes ayant beaucoup de valeur non renseinées
fig <- plot_ly(x = names(nombre), y = nombre, type = "bar", 
               xaxis = list(title = "Colonnes"), yaxis = list(title = "Nombre de -1"),
               marker = list(color = "#4C78A8"))

fig <- fig %>% layout(title = "Nombre de valeurs manquantes par colonne chez les piétons")

fig

```

Nous remarquons que locp et actp ont très peu de valeurs manquantes si nous filtrons seulement les données liées aux piétons cars elles sont liées à ces derniers, nous les conservons donc.

Nous supprimons alors les données manquante des autres colonnes et locp, actp si les usagers ne sont pas des piétons, nous conservons secu1, secu2, secu3, car les valeurs manquantes correspondent au fait qu'un usager n'ait pas de sécurité

```{r}

df_nettoye <- df[!((df$catu == 3) & ((df$locp == -1) | (df$actp == -1))), ]
colonnes <- c("atm", "col", "circ", "infra", "vma", "choc", "manv", "obs", "obsm", "grav")
df_nettoye <- df_nettoye[!apply(df_nettoye[, colonnes] == -1, 1, any),]

paste0("Nous avons supprimé ",nrow(df)-nrow(df_nettoye)," valeurs.")

```

**II - Calcul corrélations**

```{r}
library("corrplot")
library(caret)

# matrice de corrélation
corr_matrix <- cor(df_nettoye)

# affichage de la matrice
corrplot(corr_matrix, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)

# paires de variables corrélées avec une corrélation supérieure à 0.8
corr_pairs <- findCorrelation(corr_matrix, cutoff = 0.8, names = TRUE)

corr_pairs
```

Nous remarquons une forte corrélation entre "place" et "locp". En effet place nous indique précisément ou se situe un usager dans un véhicule et si l'usager est un piéton. Nous pouvons donc retirer la colonne "catu"

```{r}
df_nettoye$catu <- NULL
```

**III - Séparation des données**

```{r}
library(caret)
library(ggplot2)
library(lattice)

# Séparation des données X et y
X <- df_nettoye[, !(names(df_nettoye) %in% c("grav"))]
y <- subset(df_nettoye, select = grav)

# Normalisation des données X
X_norm <- scale(X)
 
# Ensemble d'entraînement et de test
trainIndex <- createDataPartition(y$grav, p = 0.8, list = FALSE)
X_train <- X_norm[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X_norm[-trainIndex, ]
y_test <- y[-trainIndex]

```

**IV - Réduction des caractéristiques de nos données, en utilisant Random Forest avec l'indice Gini**

```{r}
library(randomForest)

model_rf <- randomForest(factor(y_train) ~ ., data = X_train, ntree = 500)

importance_rf <- importance(model_rf)

# Graphe d'importance des caractéristiques
varImpPlot(model_rf, main="Importance des caractéristiques avec Random Forest")
```

On conserve seulement les 15 caractéristiques ayant les indices Gini les plus importantes afin de réduire la complexité de nos modèles de classifications

```{r}
df_clean <- df_nettoye[, c("catv", "manv", "secu1", "choc", "col", "catr", "obs", "vma", "locp", "secu2", "actp", "int", "lum", "obsm", "atm", "grav")]

# Séparation des données X et y
X <- df_clean[, !(names(df_clean) %in% c("grav"))]
y <- subset(df_clean, select = grav)

# Normalisation des données X
X_norm <- scale(X)
 
# Ensemble d'entraînement et de test
trainIndex <- createDataPartition(y$grav, p = 0.7, list = FALSE)
X_train <- X_norm[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X_norm[-trainIndex, ]
y_test <- y[-trainIndex]
```

**V - Visualisation PCA**

```{r}
library(plotly)

#PCA avec n =2
pca <- prcomp(X_norm, scale = FALSE, center = TRUE, rank. = min(dim(X_norm)))
PC1 <- pca$x[, 1]
PC2 <- pca$x[, 2]
data <- data.frame(PC1, PC2, y)

colors <- c("blue", "red")

# plot PCA
fig <- plot_ly(data, x = ~PC1, y = ~PC2, color = ~grav, colors = colors,
               type = "scatter", mode = "markers")
fig <- fig %>% layout(title = "Visualisation PCA des données",
                      xaxis = list(title = "PC1"),
                      yaxis = list(title = "PC2"),
                      legend = list(title = "Gravité"))

fig
```

**VI - Mise en application d'algorithmes ML**

**1 - Random Forest**

```{r}
library(randomForest)
library(caret)


set.seed(123)

temps_rf <- system.time({
model <- randomForest(factor(y_train) ~ ., data = X_train)
y_pred_rf <- predict(model, X_test)
})

confusion_matrix_rf <- table(y_test, y_pred_rf)

# précision, du recall et du F1-score du modèle
precision <- confusion_matrix_rf[1,1] / sum(confusion_matrix_rf[,1])
recall <- confusion_matrix_rf[1,1] / sum(confusion_matrix_rf[1,])
f1score <- 2 * precision * recall / (precision + recall)

precision_rf = precision
f1score_rf = f1score
```

**2 - XGboost**

```{r}
library(xgboost)

set.seed(123)

temps_xg <- system.time({
model <- xgboost(data = X_train, label = y_train, objective = "multi:softmax", nrounds = 100, num_class = 2)
y_pred_xg <- predict(model, X_test)
})

confusion_matrix_xg <- table(y_test, y_pred_xg)

# précision, du recall et du F1-score du modèle
precision <- confusion_matrix_xg[1,1] / sum(confusion_matrix_xg[,1])
recall <- confusion_matrix_xg[1,1] / sum(confusion_matrix_xg[1,])
f1score <- 2 * precision * recall / (precision + recall)

precision_xg = precision
f1score_xg = f1score
```

**3-Decision Tree**

```{r}
library(rpart)

set.seed(123)

temps_dt <- system.time({
model <- rpart(factor(y_train) ~ ., data = data.frame(X_train))
y_pred <- predict(model, data.frame(X_test), type="prob")[,2]
})

y_pred_dt <- ifelse(y_pred > 0.5, 1, 0)

confusion_matrix_dt <- table(y_test, y_pred_dt)

# précision, rappel et F1-score du modèle
precision <- confusion_matrix_dt[1,1] / sum(confusion_matrix_dt[,1])
recall <- confusion_matrix_dt[1,1] / sum(confusion_matrix_dt[1,])
f1score <- 2 * precision * recall / (precision + recall)

precision_dt <- precision
f1score_dt <- f1score
```

**4-SVM**

```{r}
library(e1071)

set.seed(123)

temps_svm <- system.time({
model <- svm(factor(y_train) ~ ., data = X_train, kernel = "rbf", cost = 1, scale = TRUE)
y_pred_svm <- predict(model, X_test)
})

confusion_matrix_svm <- table(y_test, y_pred_svm)

# précision, recall et F1-score du modèle
precision <- confusion_matrix_svm[1,1] / sum(confusion_matrix_svm[,1])
recall <- confusion_matrix_svm[1,1] / sum(confusion_matrix_svm[1,])
f1score <- 2 * precision * recall / (precision + recall)

precision_svm = precision
f1score_svm = f1score
```

```{r}
print(confusion_matrix_rf)
print(paste("Accuracy Random Forest:", precision_rf))
print(paste("F1-score Random Forest:", f1score_rf))

print(confusion_matrix_xg)
print(paste("Accuracy XGboost:", precision_xg))
print(paste("F1-score XGboost:", f1score_xg))

print(confusion_matrix_dt)
print(paste("Accuracy Decision tree:", precision_dt))
print(paste("F1-score Decision tree:", f1score_dt))

print(confusion_matrix_svm)
print(paste("Accuracy Decision tree:", precision_svm))
print(paste("F1-score Decision tree:", f1score_svm))
```

```{r}
library(ggplot2)
```

```{r}
results <- data.frame(Model = c("Random Forest", "XGboost", "Decision Tree", "SVM"),
                      F1_Score = c(f1score_rf, f1score_xg, f1score_dt, f1score_svm),
                      Precision = c(precision_rf, precision_xg, precision_dt, precision_svm))

# Graphique à barres
fig <- plot_ly(results, x = ~Model) %>%
  add_trace(y = ~F1_Score, name = "F1-Score", type = 'bar', marker = list(color = '#1f77b4')) %>%
  add_trace(y = ~Precision, name = "Précision", type = 'bar', marker = list(color = '#ff7f0e')) %>%
  layout(title = "Comparaison des F1-scores et des précisions pour chaque modèle",
         xaxis = list(title = "Modèle"),
         yaxis = list(title = ""))

fig
```

```{r}
cat("Random forest : ", format(temps_rf["elapsed"], digits = 2), "secondes\n")
cat("XGboost : ", format(temps_xg["elapsed"], digits = 2), "secondes\n")
cat("Decision Tree : ", format(temps_dt["elapsed"], digits = 2), "secondes\n")
cat("SVM : ", format(temps_svm["elapsed"], digits = 2), "secondes\n")
```

**VII - Temps d'éxécutions**

```{r}
results_time <- data.frame(Model = c("Random Forest", "XGboost", "Decision Tree", "SVM"),
                      time_exec = c(temps_rf["elapsed"], temps_xg["elapsed"], temps_dt["elapsed"], temps_svm["elapsed"]))

# Graphique à barres
fig <- plot_ly(results_time, x = ~Model) %>%
  add_trace(y = ~time_exec , name = "Temps", type = 'bar', marker = list(color = '#ff7f0e')) %>%
  layout(title = "Comparaison des temps d'éxécution pour chaque modèle",
         xaxis = list(title = "Modèle"),
         yaxis = list(title = "Time"))

fig
```
